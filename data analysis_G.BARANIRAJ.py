# -*- coding: utf-8 -*-
"""Data Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PCn1J0J1Ha5LGlTX3Ot2-yWX-yqAuB7K
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns

df = pd.read_csv("train1.csv")
df

df.shape

df.dtypes

df.count()

df.describe()

df.columns

df.isnull().sum()

df['Item_Weight']=df['Item_Weight'].fillna(df['Item_Weight'].mean())

df['Outlet_Size']=df['Outlet_Size'].fillna('Medium')

sns.distplot(df['Item_Outlet_Sales'])

sns.boxplot(df['Item_Weight'])

sns.countplot(x='Outlet_Size',data=df)

sns.countplot(df['Outlet_Location_Type'])

sns.countplot(df['Outlet_Type'])

sns.regplot(x='Item_Weight',y='Item_Outlet_Sales',data=df)

sns.boxplot(x='Outlet_Identifier',y='Item_Outlet_Sales',data=df)

sns.regplot(x='Item_Visibility',y='Item_Outlet_Sales',data=df)

plt.figure(figsize=(10,10))
sns.boxplot(x='Outlet_Size',y='Item_Outlet_Sales',data=df)

df.corr()

sns.heatmap(df.corr())

sns.regplot(x='Item_MRP',y='Item_Outlet_Sales',data=df)

sns.factorplot(x='Outlet_Type',y='Item_Outlet_Sales',hue='Outlet_Size',data=df)

sns.pairplot(df)

df['Item_Fat_Content'].unique()

def fun(x):
  if x=='Low Fat' or x=='LF' or x=='low fat':
    return(0)
  else:
    return(1)

df['Item_Fat_Content']=df['Item_Fat_Content'].apply(fun)

df['Item_Fat_Content'].head()

df['Item_Type'].unique()

df['Outlet_Size'].unique()

def fun1(x):
  if x=='Medium':
    return(0)
  elif x=='High':
    return(1)
  else:
    return(2)

df['Outlet_Size']=df['Outlet_Size'].apply(fun1)

df['Outlet_Size'].head()

df['Outlet_Location_Type'].unique()

def fun2(x):
  if x=='Tier 1':
    return(0)
  elif x=='Tier 2':
    return(1)
  else:
    return(2)

df['Outlet_Location_Type']=df['Outlet_Location_Type'].apply(fun2)

df['Outlet_Location_Type'].head()

df['Outlet_Type'].unique()

def fun3(x):
  if x=='Supermarket Type1':
    return(0)
  elif x=='Supermarket Type2':
    return(1)
  elif x=='Supermarket Type3':
    return(2)
  else:
    return(3)

df['Outlet_Type']=df['Outlet_Type'].apply(fun3)

df['Outlet_Type'].head()

df['Outlet_Identifier'].unique()

df1=pd.get_dummies(df['Outlet_Identifier'])

df=pd.concat([df,df1],axis=1)

df.columns

df.head()



"""From the co-relation map we plotted before, we can see that there almost no co-relation between 'Item_Identifier', 'Item_type' and 'Outlet_Establishment_year' with our target i.e 'Item_Outlet_sales'

So we will drop these columns and will not use in training out model.
"""

x=df.drop(['Item_Identifier','Item_Type','Outlet_Establishment_Year','Item_Outlet_Sales','Outlet_Identifier'],axis=1)
y=df['Item_Outlet_Sales']

x.head()



y.head()

from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error,mean_absolute_error,accuracy_score,classification_report,confusion_matrix

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)

from sklearn.linear_model import LinearRegression

lrm=LinearRegression()

lrm.fit(x_train,y_train)

predicted=lrm.predict(x_test)

print("MEAN SQUARED ERROR(MSE)",mean_squared_error(y_test,predicted))
print("MEAN ABSOLUTE ERROR(MAE)",mean_absolute_error(y_test,predicted))
print("ROOT MEAN SQUARED ERROR(RMSE)",np.sqrt(mean_squared_error(y_test,predicted)))
print("SCORE",lrm.score(x_test,y_test))

from sklearn.ensemble import RandomForestRegressor

rfg=RandomForestRegressor()

rfg.fit(x_train,y_train)

predicted=rfg.predict(x_test)

print("MEAN SQUARED ERROR(MSE)",mean_squared_error(y_test,predicted))
print("MEAN ABSOLUTE ERROR(MAE)",mean_absolute_error(y_test,predicted))
print("ROOT MEAN SQUARED ERROR(RMSE)",np.sqrt(mean_squared_error(y_test,predicted)))
print("SCORE",rfg.score(x_test,y_test))

from sklearn.ensemble import AdaBoostRegressor

abr=AdaBoostRegressor(n_estimators=70)

abr.fit(x_train,y_train)

predicted=abr.predict(x_test)

print("MEAN SQUARED ERROR(MSE)",mean_squared_error(y_test,predicted))
print("MEAN ABSOLUTE ERROR(MAE)",mean_absolute_error(y_test,predicted))
print("ROOT MEAN SQUARED ERROR(RMSE)",np.sqrt(mean_squared_error(y_test,predicted)))
print("SCORE",abr.score(x_test,y_test))

from sklearn.ensemble import BaggingRegressor

br=BaggingRegressor(n_estimators=30)

br.fit(x_train,y_train)

predicted=br.predict(x_test)

print("MEAN SQUARED ERROR(MSE)",mean_squared_error(y_test,predicted))
print("MEAN ABSOLUTE ERROR(MAE)",mean_absolute_error(y_test,predicted))
print("ROOT MEAN SQUARED ERROR(RMSE)",np.sqrt(mean_squared_error(y_test,predicted)))
print("SCORE",br.score(x_test,y_test))

"""Linear Regression score: 0.56

Random Forest Regression Score: 0.55

AdaBoost Regression Score: 0.46

Bagging Regressor Score 0.54

We can see that Linear Regression model gave us the best score for our testing data. Therefore Linear Regression is best from all the above models.

Summary

Firstly we studied about the dataset i.e Big Mart Sales Analysis and understood the meaning of each columns. Then we performed Exploratory Data Analysis on our dataset. We plotted various Univariate and Bi-variate plots to study the relationship between various features. Then we cleaned our data and also performed feature enginnering.
We trained our model and predicted values for Outlet_sales. Evaluation was done to find out the best model.

Conclusion

From all the models that we used, we found out that Linear Regression model gave us the best score i.e 0.56. We therefore end our analysis here and conclude Linear regression as our predictive model.
"""